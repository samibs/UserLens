# Design Document: Caching and Incremental Processing for UserLens

**Version:** 1.0
**Date:** 2025-06-04

## 1. Introduction

This document outlines a strategy for implementing caching and incremental processing within the UserLens application. The goal is to significantly speed up the `analyze` and `generate` commands, particularly for large projects where only a few files change between runs. This will improve the developer experience and efficiency of using UserLens.

## 2. Goals

*   Reduce redundant work during analysis by processing only new or modified files.
*   Reduce redundant work during documentation generation by regenerating only affected files.
*   Maintain the accuracy and completeness of the analysis and generated documentation.
*   Provide a noticeable performance improvement for users.

## 3. Proposed Caching Mechanism

### 3.1. What to Cache

The primary unit of caching will be the analysis result for individual component files.

*   **Individual Component Analysis Result:** The `ComponentMetadata` object produced by `ReactAnalyzer.parseComponent()` for each component file. This includes name, filePath, props, userActions, semanticCategory, and description.
*   **File Content Hash:** An MD5 or SHA1 hash of each analyzed source file's content. This will be used for cache invalidation.
*   **(Optional) Abstract Syntax Tree (AST):** The AST generated by `@babel/parser`. Caching this could offer further speedups if re-analysis involves re-using the AST but re-running later stages (e.g., NLP). Initially, we can omit this for simplicity.
*   **(Optional) Intermediate NLP Results:** If NLP steps within `ReactAnalyzer` are particularly time-consuming and can be isolated, their results could also be cached per component. Initially, we will cache the final `ComponentMetadata`.

### 3.2. Cache Storage

*   **Location:** A hidden directory named `.userlens_cache/` will be created in the root of the user's project (alongside `userlens.config.json`). This keeps the cache local to the project and easily clearable.
*   **Structure:**
    *   `.userlens_cache/metadata/`: This directory will store the cached `ComponentMetadata`.
        *   Each cached item will be a JSON file, named using a hash of the component's relative file path to avoid issues with long paths or special characters. For example, `md5(src/components/Button.tsx).json`.
        *   Each JSON file will contain:
            ```json
            {
              "sourceFileHash": "content_hash_of_the_original_file",
              "componentMetadata": { ... } // The ComponentMetadata object
            }
            ```
    *   `.userlens_cache/cache_info.json`: A top-level file in the cache directory to store cache-wide information.
        ```json
        {
          "version": "1.0", // Cache structure/logic version
          "created": "timestamp"
        }
        ```

### 3.3. Cache Invalidation

*   **Primary Method: File Content Hash:**
    *   Before analyzing a file, UserLens will calculate the hash of its current content.
    *   This hash will be compared against the `sourceFileHash` stored in the cached metadata for that file.
    *   If the hashes differ, or if the file is not in the cache, it will be re-analyzed.
*   **Cache Versioning:**
    *   The `cache_info.json` will store a `version`. If the UserLens analysis logic changes significantly in a new release, this version can be incremented. UserLens will then treat the existing cache as stale and re-analyze all files. This ensures that changes in the analyzer itself are reflected.
*   **Handling Deleted Files:** If a file path previously in the cache is no longer found during a project scan, its corresponding cache entry will be removed.

## 4. Incremental Analysis (`analyze` command)

The `analyze` command will be modified to perform incremental analysis.

### 4.1. Modified Analysis Workflow

```mermaid
graph TD
    A[Start 'analyze' command] --> B{Load UserLens Config};
    B --> C[Scan project for component files (e.g., `findComponentFiles`)];
    C --> D[Initialize empty list: `currentComponents`];
    C --> E[Initialize empty list: `changedOrNewFilePaths`];
    C --> F[Initialize empty list: `deletedFilePaths`];
    C --> G[Load existing cache index (file paths and their stored content hashes)];
    G --> H{For each component file found in project};
    H -- File Found --> I[Calculate content hash of file];
    I --> J{Cache exists for file AND hash matches?};
    J -- Yes (Cache Hit) --> K[Load `ComponentMetadata` from cache];
    K --> L[Add to `currentComponents`];
    J -- No (Cache Miss / Stale) --> M[Call `analyzer.parseComponent(file)`];
    M --> N[Store new `ComponentMetadata` & content hash in cache];
    N --> O[Add to `currentComponents`];
    O --> P[Add file path to `changedOrNewFilePaths`];
    L --> Q{Next file?};
    P --> Q;
    Q -- No more files --> R[Identify deleted files (in cache index but not in project scan)];
    R --> S[Add to `deletedFilePaths`];
    S --> T[Remove deleted files' data from cache];
    T --> U[Generate `components.json` from `currentComponents`];
    U --> V[Re-calculate `patterns.json` based on `currentComponents`];
    V --> W[Re-calculate `workflows.json` based on `currentComponents`];
    W --> X[Store `changedOrNewFilePaths` and `deletedFilePaths` for 'generate' step (e.g., in `userlens-analysis/changeset.json`)];
    X --> Y[End 'analyze'];
```

### 4.2. Detailed Steps:

1.  **Load Configuration:** Load UserLens configuration.
2.  **Initialize Cache Manager:** Instantiate a `CacheManager` responsible for all cache interactions.
3.  **Scan Project Files:** Use the existing `findComponentFiles` logic to get a list of all potential component files in the project.
4.  **Process Each File:**
    *   For each `filePath` identified:
        *   Calculate its current content hash.
        *   Query the `CacheManager` for a cached entry for this `filePath`.
        *   **Cache Hit:** If an entry exists and its stored `sourceFileHash` matches the current content hash, retrieve the `ComponentMetadata` from the cache.
        *   **Cache Miss/Stale:** If no entry exists or the hash mismatches, call `analyzer.parseComponent(filePath)` to get fresh `ComponentMetadata`. Store this new metadata and the current content hash in the cache via the `CacheManager`. Mark this file as "changed" or "new".
    *   Collect all `ComponentMetadata` (from cache or fresh analysis) into a list (`allComponentsMetadata`).
5.  **Handle Deleted Files:**
    *   Compare the list of currently found project files against the file paths known to the cache (e.g., from a cache index or by listing cached files).
    *   Any file path in the cache but not in the current project scan is considered "deleted".
    *   Remove entries for these deleted files from the `CacheManager`. Mark these files as "deleted".
6.  **Update Aggregated Results:**
    *   The `allComponentsMetadata` list now represents the complete and up-to-date set of components.
    *   Overwrite [`userlens-analysis/components.json`](./userlens-analysis/components.json:0) with `allComponentsMetadata`.
    *   Re-run `patternMatcher.detectPatterns(allComponentsMetadata)` and `patternMatcher.detectWorkflows(allComponentsMetadata)` using the full, current list.
    *   Overwrite [`userlens-analysis/patterns.json`](./userlens-analysis/patterns.json:0) and [`userlens-analysis/workflows.json`](./userlens-analysis/workflows.json:0).
7.  **Record Changeset:**
    *   Create a `changeset.json` file in the `userlens-analysis` directory. This file will list:
        *   Paths of new components.
        *   Paths of changed components.
        *   Paths of deleted components.
        *   Flags indicating if `components.json`, `patterns.json`, or `workflows.json` actually changed content compared to their previous state (requires comparing hashes of these files before and after writing).

    Example `changeset.json`:
    ```json
    {
      "newComponents": ["src/components/NewFeature.tsx"],
      "changedComponents": ["src/components/Button.tsx"],
      "deletedComponents": ["src/legacy/OldWidget.jsx"],
      "componentsJsonChanged": true,
      "patternsJsonChanged": false,
      "workflowsJsonChanged": true
    }
    ```

## 5. Incremental Generation (`generate` command)

The `generate` command will use the `changeset.json` (produced by `analyze`) and the cache to determine which documentation files need regeneration.

### 5.1. Modified Generation Workflow

```mermaid
graph TD
    AA[Start 'generate' command] --> AB{Load `changeset.json` from `userlens-analysis`};
    AB -- No changeset or no changes --> AZ[End 'generate' (Nothing to do)];
    AB -- Changes detected --> AC[Load `components.json`, `patterns.json`, `workflows.json`];
    AC --> AD{For each new/changed component in changeset};
    AD -- Yes --> AE[Regenerate specific component's .md file (e.g., `features/.../component.md`)];
    AE --> AF{Next new/changed component?};
    AF -- No --> AG;
    AD -- No --> AG;
    AG{For each deleted component in changeset};
    AG -- Yes --> AH[Delete specific component's .md file];
    AH --> AI{Next deleted component?};
    AI -- No --> AJ;
    AG -- No --> AJ;
    AJ{Any components new/changed/deleted OR patternsJsonChanged OR workflowsJsonChanged?};
    AJ -- Yes --> AK[Regenerate overview files (index.md, overview.md, category overviews, workflow index)];
    AK --> AZ;
    AJ -- No --> AZ;
```

### 5.2. Detailed Steps:

1.  **Read Changeset:** Load `changeset.json` from the `userlens-analysis` directory. If it doesn't exist or indicates no relevant changes, the command might exit early.
2.  **Load Analysis Results:** Load [`components.json`](./userlens-analysis/components.json:0), [`patterns.json`](./userlens-analysis/patterns.json:0), and [`workflows.json`](./userlens-analysis/workflows.json:0).
3.  **Process New/Changed Components:**
    *   For each file path in `newComponents` or `changedComponents` from the changeset:
        *   Find the corresponding `ComponentMetadata` from the loaded `components.json`.
        *   Determine the output path for this component's documentation file (e.g., `features/<category>/<componentName>.md`).
        *   Call the relevant `MarkdownGenerator` method (e.g., `generateComponentDoc()`) to regenerate this specific file.
4.  **Process Deleted Components:**
    *   For each file path in `deletedComponents`:
        *   Determine the output path of the documentation file that corresponded to this component.
        *   Delete this markdown file.
5.  **Update Structural/Overview Files:**
    *   If `changeset.json` indicates that any components were added, changed, or deleted, OR if `patternsJsonChanged` or `workflowsJsonChanged` is true:
        *   Regenerate `index.md` (main index).
        *   Regenerate `overview.md`.
        *   Regenerate all category overview files (e.g., `features/<category>/overview.md`) because their lists of components might have changed.
        *   Regenerate `workflows/index.md`.
        *   The `MarkdownGenerator` methods like `generateIndex`, `generateOverview`, `generateCategoryOverview`, `generateWorkflows` (for its index part) will be called.

### 5.3. Granularity of Regeneration

This approach provides a good balance:
*   Individual component docs are only touched if the component itself changes or is new/deleted.
*   Overview and index files are regenerated if their underlying data (set of components, patterns, workflows) changes.

A simpler initial step could be: if `changeset.json` indicates *any* change, regenerate *all* documentation. This would still benefit from faster analysis but defer the complexity of incremental generation. However, the proposed approach is more aligned with the goals.

## 6. Impact on Existing Code

*   **[`src/cli/index.ts`](./src/cli/index.ts:0):**
    *   **`analyze` command:** Significant refactoring to incorporate the caching logic, file hash comparisons, interaction with `CacheManager`, and generation of `changeset.json`.
    *   **`generate` command:** Modified to read `changeset.json` and selectively call `MarkdownGenerator` methods or delete files.
*   **[`src/analyzers/react/react-analyzer.ts`](./src/analyzers/react/react-analyzer.ts:9):**
    *   No direct changes anticipated. It will continue to analyze a single file and return `ComponentMetadata`.
*   **[`src/generators/markdown/markdown-generator.ts`](./src/generators/markdown/markdown-generator.ts:6):**
    *   Methods like `generateComponentDoc`, `generateCategoryOverview`, `generateIndex`, etc., should be robust enough to be called individually by the CLI based on the changeset. The current structure seems largely amenable to this.
*   **New `CacheManager` Module:**
    *   A new class/module (e.g., `src/cache/cache-manager.ts`) will be created to encapsulate all cache operations:
        *   Reading/writing cached `ComponentMetadata`.
        *   Calculating file hashes.
        *   Managing the cache index and version.
        *   Deleting cache entries.
*   **[`src/models/interfaces.ts`](./src/models/interfaces.ts:0):**
    *   No immediate changes to `ConfigOptions` are strictly necessary for caching itself, but options to disable caching or specify cache location could be added later.
*   **Helper Utilities:**
    *   Functions for file hashing.

## 7. Trade-offs

*   **Complexity vs. Performance Gain:**
    *   The proposed incremental logic, especially for `generate`, introduces complexity. This is justified by the expected performance gains on large projects with frequent small changes.
*   **Cache Storage Size:**
    *   The `.userlens_cache/` directory will consume disk space, proportional to the number of components and the size of their metadata. This is generally acceptable. A `userlens clear-cache` command should be added.
*   **Hash Calculation Overhead:**
    *   Calculating content hashes for each file on each run adds a small overhead. This is typically negligible compared to parsing and NLP.
*   **Correctness of Invalidation:**
    *   Content hash-based invalidation is robust. Cache versioning handles changes in UserLens's own logic.
*   **Initial Run Performance:** The very first run of `analyze` on a project will be similar to current performance (as everything is a cache miss), potentially slightly slower due to hash calculations and cache writing. Subsequent runs will see the benefits.

## 8. Future Considerations / Open Questions

*   **Cache Pruning:** Implement a strategy for pruning very old or orphaned cache entries beyond just deleted files from the last run.
*   **User Configuration for Cache:** Allow users to disable caching or change the cache location via `userlens.config.json`.
*   **AST Caching:** Evaluate if caching ASTs provides significant additional benefit for the added complexity.
*   **Error Handling:** Robust error handling for cache read/write operations. What happens if the cache is corrupted? (Safest is to invalidate and rebuild).
*   **Testing:** Thorough testing of cache hits, misses, invalidation, and incremental generation logic will be crucial.

## 9. Summary

This design proposes a robust caching mechanism using file content hashes and a structured cache directory. Incremental analysis will process only new or changed files, and incremental generation will update only the necessary documentation files based on a changeset. This approach aims to significantly improve UserLens performance for iterative development workflows.